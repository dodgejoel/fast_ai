{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Farm Challenge\n",
    "\n",
    "1. Data are prepared in their directories\n",
    "2. What about a way to spin up vgg16 quickly - lets actually save the model somewhere here so we can just load it directly. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import re\n",
    "import csv\n",
    "from numpy.random import permutation\n",
    "from utils.utils import plots\n",
    "import glob\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "pname = 'state_farm_challenge'\n",
    "batch_size = 64\n",
    "proot = '/home/ubuntu/nbs/data/statefarm/'\n",
    "# proot = '/home/ubuntu/nbs/data/statefarm/sample'\n",
    "models_path = path.join(proot, 'models')\n",
    "if not path.exists(models_path):\n",
    "    os.makedirs(models_path)\n",
    "\n",
    "\n",
    "def ConvBlock(layers, model, filters):\n",
    "    # I don't know what all of these separate componenets do but together\n",
    "    # they constitute a convolutional layer in a deep nn\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "def DenseBlock(model):\n",
    "    # this is pretty standard\n",
    "    # i expect that there will be a final dense output layer with dimension num_classes\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "VGG_MEAN = np.array([123.68, 116.779, 103.939]).reshape((3, 1, 1))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - VGG_MEAN\n",
    "    return x[:, ::-1]\n",
    "\n",
    "def _make_architecture():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3, 224, 224)))\n",
    "    \n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    DenseBlock(model)\n",
    "    DenseBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def _initialize_model_weights(model):    \n",
    "    fpath = get_file('vgg16.h5', 'http://files.fast.ai/models/vgg16.h5', cache_subdir='models')\n",
    "    model.load_weights(fpath)\n",
    "    \n",
    "def make_vgg():\n",
    "    model = _make_architecture()\n",
    "    _initialize_model_weights(model)\n",
    "    return model\n",
    "\n",
    "def get_batches(\n",
    "    dirname,  # eg valid or train\n",
    "    gen=image.ImageDataGenerator(),  # keras utility\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # no idea\n",
    "):\n",
    "    return gen.flow_from_directory(\n",
    "    path.join(proot, dirname),\n",
    "    target_size=(224, 224),  # hardcoded for our context\n",
    "    class_mode=class_mode,\n",
    "    shuffle=shuffle,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "def train_model(model, batches, val_batches, epochs=1, model_tag=pname):\n",
    "    # train the model over these batches (and these validation batches) for this many epochs\n",
    "    # once finished nondestructively save the model to a path dictated by weights_tag parameter\n",
    "    model.fit_generator(\n",
    "        batches,\n",
    "        samples_per_epoch=batches.nb_sample,\n",
    "        nb_epoch=epochs,\n",
    "        validation_data=val_batches,\n",
    "        nb_val_samples=val_batches.nb_sample,    \n",
    "    )\n",
    "    saves = glob.glob(models_path + '%s*' % model_tag)\n",
    "    num = [int(f[-f[::-1].find('_'):-3]) for f in saves]\n",
    "    fname = '%s_%d.h5' % (model_tag, max(num or [0]) + 1)\n",
    "    model.save_weights(path.join(models_path, fname))\n",
    "\n",
    "\n",
    "def display_validation(model, val_batches, num=4):\n",
    "    def plots_idx(idxs, titles, filenames):\n",
    "        if len(idxs):\n",
    "            plots([image.load_img(path.join(proot, 'valid', filenames[i])) for i in idxs], titles=titles)\n",
    "        else:\n",
    "            print('none!')\n",
    "\n",
    "    labels = val_batches.classes\n",
    "    probs = model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "    preds = np.argmax(probs, 1)\n",
    "    filenames = val_batches.filenames\n",
    "\n",
    "    correct = permutation(np.where(preds == labels)[0])[:num]\n",
    "    incorrect = permutation(np.where(preds != labels)[0])[:num]\n",
    "    \n",
    "    print('correct sample')\n",
    "    plots_idx(correct, preds[correct], filenames)\n",
    "    print('incorrect sample')\n",
    "    plots_idx(incorrect, preds[incorrect], filenames)\n",
    "    \n",
    "    for i in range(val_batches.nb_class):\n",
    "        # dogs we got wrong\n",
    "        print('missed from class %d' % i)\n",
    "        miss_idxs = np.where((labels == i) & (labels != preds))[0]\n",
    "        worst_idxs = np.argsort(probs[miss_idxs][:, i])[:num]\n",
    "        missed_dogs_idxs = miss_idxs[worst_idxs]\n",
    "        plots_idx(missed_dogs_idxs, probs[missed_dogs_idxs][:, i], filenames)\n",
    "        \n",
    "        # dogs we got right\n",
    "        print('hits from class %d' % i)\n",
    "        hit_idxs = np.where((labels == i) & (labels == preds))[0]\n",
    "        best_idxs = np.argsort(probs[hit_idxs][:, i])[::-1][:num]\n",
    "        hit_dogs_idxs = hit_idxs[best_idxs]\n",
    "        plots_idx(hit_dogs_idxs, probs[hit_dogs_idxs][:, i], filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune(model, classes, lr=.001):\n",
    "    model.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "def prepare_submission(model, clip=(.05, .95)):\n",
    "    test_batches = get_batches('test', shuffle=False, batch_size=64, class_mode=None)\n",
    "    predictions = model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "    clipped = np.clip(predictions, .05, .95)\n",
    "    f = open(path.join(proot, pname + '_submission.csv'), 'w')\n",
    "    writer = csv.Writer(f)\n",
    "    writer.writerow(['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    for filename, ps in itertools.izip(test_batches.filenames, clipped_predictions):\n",
    "        writer.writerow([filename] + list(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20187 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/5\n",
      "20187/20187 [==============================] - 588s - loss: 1.8760 - acc: 0.4677 - val_loss: 0.5167 - val_acc: 0.8552\n",
      "Epoch 2/5\n",
      "20187/20187 [==============================] - 588s - loss: 1.0629 - acc: 0.6628 - val_loss: 0.4159 - val_acc: 0.8762\n",
      "Epoch 3/5\n",
      "20187/20187 [==============================] - 588s - loss: 0.9387 - acc: 0.7005 - val_loss: 0.2992 - val_acc: 0.9218\n",
      "Epoch 4/5\n",
      "20187/20187 [==============================] - 588s - loss: 0.8943 - acc: 0.7179 - val_loss: 0.3055 - val_acc: 0.9115\n",
      "Epoch 5/5\n",
      "20187/20187 [==============================] - 588s - loss: 0.8680 - acc: 0.7248 - val_loss: 0.2894 - val_acc: 0.9093\n"
     ]
    }
   ],
   "source": [
    "model = make_vgg()\n",
    "finetune(model, 10)\n",
    "train_batches = get_batches('train')\n",
    "valid_batches = get_batches('valid', shuffle=False)\n",
    "train_model(model, train_batches, valid_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_validation(model, valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches('test', shuffle=False, batch_size=64, class_mode=None)\n",
    "predictions = model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "clipped = np.clip(predictions, .05, .95)\n",
    "with open(path.join(proot, pname + '_submission.csv'), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    for filename, ps in itertools.izip(test_batches.filenames, clipped):\n",
    "        writer.writerow([filename] + list(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.4168e-01,   1.1886e-04,   2.2242e-04,   5.4664e-04,   3.5171e-01,   6.1181e-06,\n",
       "         3.2724e-03,   5.1362e-05,   6.4707e-04,   1.7532e-03], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img',\n",
       " 0.34027249,\n",
       " 0.00084958336,\n",
       " 2.8812028e-05,\n",
       " 0.00078424788,\n",
       " 0.021131529,\n",
       " 0.082023025,\n",
       " 0.24896514,\n",
       " 0.0010023912,\n",
       " 0.063092291,\n",
       " 0.24185042]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape\n",
    "['img'] + list(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
